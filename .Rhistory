firmNAME<-gsub("&","%26",firmNAME)
FIRMurl<-paste0("https://api.companieshouse.gov.uk/search/companies?q=",firmNAME)
firmTEST<-httr::GET(FIRMurl, httr::authenticate(mkey, ""))
firmTEXT<-httr::content(firmTEST, as="text")
JLfirm<-jsonlite::fromJSON(firmTEXT, flatten=TRUE)
MM<-JLfirm$total_results
MM2<-MM/JLfirm$items_per_page
MM2b<-ceiling(MM2)
DFfirmL<-list()
for (j in 1:MM2b){
FIRMurl2<-paste0("https://api.companieshouse.gov.uk/search/companies?q=",firmNAME,"&page_number=",j)
firmTEST2<-httr::GET(FIRMurl2, httr::authenticate(mkey, ""))
firmTEXT2<-httr::content(firmTEST2, as="text")
JLfirm2<-jsonlite::fromJSON(firmTEXT2, flatten=TRUE)
DFfirmL[[j]]<-JLfirm2
}
DFfirm<-plyr::ldply(DFfirmL,data.frame)
DFfirmNAMES<-DFfirm$items.title
DFfirmNUMBER<-as.character(DFfirm$items.company_number)
DFfirmDateofCreation<-DFfirm$items.date_of_creation
DFfirmTYPE<-DFfirm$items.company_type
DFfirmSTATUS<-DFfirm$items.company_status
DFfirmADDRESS<-DFfirm$items.address_snippet
#DFfirmCOUNTRY<-DFfirm$items.address.country
DFfirmLOCAL<-DFfirm$items.address.locality
DFfirmPOSTCODE<-DFfirm$items.address.postal_code
myDf <- data.frame(
id.search.term = company,
company.name=DFfirmNAMES,
company.number = DFfirmNUMBER,
Date.of.Creation = DFfirmDateofCreation,
company.type = DFfirmTYPE,
company.status = DFfirmSTATUS,
address = DFfirmADDRESS,
Locality = DFfirmLOCAL,
postcode = DFfirmPOSTCODE)
return
}
CompanySearch("GFK INVESTMENTS LLP", mkey)
CompanySearch <- function(company,mkey) {
firmNAME<-gsub(" ", "+",company)
firmNAME<-gsub("&","%26",firmNAME)
FIRMurl<-paste0("https://api.companieshouse.gov.uk/search/companies?q=",firmNAME)
firmTEST<-httr::GET(FIRMurl, httr::authenticate(mkey, ""))
firmTEXT<-httr::content(firmTEST, as="text")
JLfirm<-jsonlite::fromJSON(firmTEXT, flatten=TRUE)
MM<-JLfirm$total_results
MM2<-MM/JLfirm$items_per_page
MM2b<-ceiling(MM2)
DFfirmL<-list()
for (j in 1:MM2b){
FIRMurl2<-paste0("https://api.companieshouse.gov.uk/search/companies?q=",firmNAME,"&page_number=",j)
firmTEST2<-httr::GET(FIRMurl2, httr::authenticate(mkey, ""))
firmTEXT2<-httr::content(firmTEST2, as="text")
JLfirm2<-jsonlite::fromJSON(firmTEXT2, flatten=TRUE)
DFfirmL[[j]]<-JLfirm2
}
DFfirm<-plyr::ldply(DFfirmL,data.frame)
DFfirmNAMES<-DFfirm$items.title
DFfirmNUMBER<-as.character(DFfirm$items.company_number)
DFfirmDateofCreation<-DFfirm$items.date_of_creation
DFfirmTYPE<-DFfirm$items.company_type
DFfirmSTATUS<-DFfirm$items.company_status
DFfirmADDRESS<-DFfirm$items.address_snippet
#DFfirmCOUNTRY<-DFfirm$items.address.country
DFfirmLOCAL<-DFfirm$items.address.locality
DFfirmPOSTCODE<-DFfirm$items.address.postal_code
myDf <- data.frame(
id.search.term = company,
company.name=DFfirmNAMES,
company.number = DFfirmNUMBER,
Date.of.Creation = DFfirmDateofCreation,
company.type = DFfirmTYPE,
company.status = DFfirmSTATUS,
address = DFfirmADDRESS,
Locality = DFfirmLOCAL,
postcode = DFfirmPOSTCODE)
return
}
mkey <- 'rgORvmllH4onBqmb0Gh5pOeW6zIB_G3zaavbgPyg'
CompanySearch("GFK INVESTMENTS LLP", mkey)
company <- "GFK INVESTMENTS LLP"
CompanySearch <- function(company,mkey) {
firmNAME<-gsub(" ", "+",company)
firmNAME<-gsub("&","%26",firmNAME)
FIRMurl<-paste0("https://api.companieshouse.gov.uk/search/companies?q=",firmNAME)
firmTEST<-httr::GET(FIRMurl, httr::authenticate(mkey, ""))
firmTEXT<-httr::content(firmTEST, as="text")
JLfirm<-jsonlite::fromJSON(firmTEXT, flatten=TRUE)
MM<-JLfirm$total_results
MM2<-MM/JLfirm$items_per_page
MM2b<-ceiling(MM2)
DFfirmL<-list()
for (j in 1:MM2b){
FIRMurl2<-paste0("https://api.companieshouse.gov.uk/search/companies?q=",firmNAME,"&page_number=",j)
firmTEST2<-httr::GET(FIRMurl2, httr::authenticate(mkey, ""))
firmTEXT2<-httr::content(firmTEST2, as="text")
JLfirm2<-jsonlite::fromJSON(firmTEXT2, flatten=TRUE)
DFfirmL[[j]]<-JLfirm2
}
DFfirm<-plyr::ldply(DFfirmL,data.frame)
DFfirmNAMES<-DFfirm$items.title
DFfirmNUMBER<-as.character(DFfirm$items.company_number)
DFfirmDateofCreation<-DFfirm$items.date_of_creation
DFfirmTYPE<-DFfirm$items.company_type
DFfirmSTATUS<-DFfirm$items.company_status
DFfirmADDRESS<-DFfirm$items.address_snippet
#DFfirmCOUNTRY<-DFfirm$items.address.country
DFfirmLOCAL<-DFfirm$items.address.locality
DFfirmPOSTCODE<-DFfirm$items.address.postal_code
myDf <- data.frame(
id.search.term = company,
company.name=DFfirmNAMES,
company.number = DFfirmNUMBER,
Date.of.Creation = DFfirmDateofCreation,
company.type = DFfirmTYPE,
company.status = DFfirmSTATUS,
address = DFfirmADDRESS,
Locality = DFfirmLOCAL,
postcode = DFfirmPOSTCODE)
return
}
CompanySearch(company, mkey)
company <- "unilever"
CompanySearch <- function(company,mkey) {
firmNAME<-gsub(" ", "+",company)
firmNAME<-gsub("&","%26",firmNAME)
FIRMurl<-paste0("https://api.companieshouse.gov.uk/search/companies?q=",firmNAME)
firmTEST<-httr::GET(FIRMurl, httr::authenticate(mkey, ""))
firmTEXT<-httr::content(firmTEST, as="text")
JLfirm<-jsonlite::fromJSON(firmTEXT, flatten=TRUE)
MM<-JLfirm$total_results
MM2<-MM/JLfirm$items_per_page
MM2b<-ceiling(MM2)
DFfirmL<-list()
for (j in 1:MM2b){
FIRMurl2<-paste0("https://api.companieshouse.gov.uk/search/companies?q=",firmNAME,"&page_number=",j)
firmTEST2<-httr::GET(FIRMurl2, httr::authenticate(mkey, ""))
firmTEXT2<-httr::content(firmTEST2, as="text")
JLfirm2<-jsonlite::fromJSON(firmTEXT2, flatten=TRUE)
DFfirmL[[j]]<-JLfirm2
}
DFfirm<-plyr::ldply(DFfirmL,data.frame)
DFfirmNAMES<-DFfirm$items.title
DFfirmNUMBER<-as.character(DFfirm$items.company_number)
DFfirmDateofCreation<-DFfirm$items.date_of_creation
DFfirmTYPE<-DFfirm$items.company_type
DFfirmSTATUS<-DFfirm$items.company_status
DFfirmADDRESS<-DFfirm$items.address_snippet
#DFfirmCOUNTRY<-DFfirm$items.address.country
DFfirmLOCAL<-DFfirm$items.address.locality
DFfirmPOSTCODE<-DFfirm$items.address.postal_code
myDf <- data.frame(
id.search.term = company,
company.name=DFfirmNAMES,
company.number = DFfirmNUMBER,
Date.of.Creation = DFfirmDateofCreation,
company.type = DFfirmTYPE,
company.status = DFfirmSTATUS,
address = DFfirmADDRESS,
Locality = DFfirmLOCAL,
postcode = DFfirmPOSTCODE)
return
}
CompanySearch(company, mkey)
library(jsonlite)
library(dplyr)
library(httr)
library(jsonlite)
library(dplyr)
library(plyr)
library(plyr)
library(dplyr)
mkey <- 'rgORvmllH4onBqmb0Gh5pOeW6zIB_G3zaavbgPyg'
company <- "unilever"
CompanySearch <- function(company, mkey) {
firmNAME <- gsub(" ", "+", company)
firmNAME <- gsub("&","%26", firmNAME)
FIRMurl <- paste0("https://api.companieshouse.gov.uk/search/companies?q=", firmNAME)
firmTEST <- httr::GET(FIRMurl, httr::authenticate(mkey, ""))
firmTEXT <- httr::content(firmTEST, as = "text")
JLfirm <- jsonlite::fromJSON(firmTEXT, flatten=TRUE)
MM <- JLfirm$total_results
MM2 <- MM/JLfirm$items_per_page
MM2b <- ceiling(MM2)
DFfirmL <- list()
for (j in 1:MM2b){
FIRMurl2<-paste0("https://api.companieshouse.gov.uk/search/companies?q=", firmNAME, "&page_number=",j)
firmTEST2 <- httr::GET(FIRMurl2, httr::authenticate(mkey, ""))
firmTEXT2 <- httr::content(firmTEST2, as = "text")
JLfirm2 <- jsonlite::fromJSON(firmTEXT2, flatten = TRUE)
DFfirmL[[j]] <- JLfirm2
}
DFfirm<-plyr::ldply(DFfirmL, data.frame)
DFfirmNAMES <- DFfirm$items.title
DFfirmNUMBER <- as.character(DFfirm$items.company_number)
DFfirmDateofCreation <- DFfirm$items.date_of_creation
DFfirmTYPE <- DFfirm$items.company_type
DFfirmSTATUS <- DFfirm$items.company_status
DFfirmADDRESS <- DFfirm$items.address_snippet
#DFfirmCOUNTRY<-DFfirm$items.address.country
DFfirmLOCAL <- DFfirm$items.address.locality
DFfirmPOSTCODE <- DFfirm$items.address.postal_code
myDf <- data.frame(
id.search.term = company,
company.name=DFfirmNAMES,
company.number = DFfirmNUMBER,
Date.of.Creation = DFfirmDateofCreation,
company.type = DFfirmTYPE,
company.status = DFfirmSTATUS,
address = DFfirmADDRESS,
Locality = DFfirmLOCAL,
postcode = DFfirmPOSTCODE)
return(myDf)
}
CompanySearch(company, mkey)
mkey <- 'rgORvmllH4onBqmb0Gh5pOeW6zIB_G3zaavbgPyg'
company <- "unilever"
gsub(" ", "+", company)
firmNAME <- gsub(" ", "+", company)
gsub("&","%26", firmNAME)
firmNAME <- gsub("&","%26", firmNAME)
FIRMurl <- paste0("https://api.companieshouse.gov.uk/search/companies?q=", firmNAME)
FIRMurl
firmTEST <- httr::GET(FIRMurl, httr::authenticate(mkey, ""))
firmTEST
FIRMurl <- paste0("https://api.companieshouse.gov.uk/search/companies/q=", firmNAME)
firmTEST <- httr::GET(FIRMurl, httr::authenticate(mkey, ""))
firmTEST
httr::GET(FIRMurl, httr::authenticate(mkey, ""))
mkey <- 'rgORvmllH4onBqmb0Gh5pOeW6zIB_G3zaavbgPyg'
GET("https://api.companieshouse.gov.uk/search/companies")
GET("https://api.companieshouse.gov.uk/search/companies/")
GET("https://api.companieshouse.gov.uk/search/companies/", httr::authenticate(mkey, ""))
GET("https://api.companieshouse.gov.uk/search/companies/", httr::authenticate(mkey))
GET("https://api.companieshouse.gov.uk/search/companies/", httr::authenticate(mkey))
GET("https://api.companieshouse.gov.uk/search/companies/", config = mkey)
FIRMurl <- paste0("https://api.companieshouse.gov.uk/search/companies/q=", firmNAME)
httr::GET(FIRMurl, httr::authenticate(mkey, ""))
httr::GET(url = FIRMurl, config = list(httr::authenticate(mkey, "")))
httr::GET(url = FIRMurl, config = config(token = mkey))
FIRMurl
httr::GET(url = FIRMurl, config = config(token = mkey))
url <- paste('"https://api.companieshouse.gov.uk/search/companies/', mkey, sep='')
mydata <- GET(url, config = add_headers(paste0("Basic ", req_token)))
mydata <- GET(url, config = add_headers(paste0("Basic ", mkey)))
url <- paste('"https://api.companieshouse.gov.uk/search/companies/')
url <- 'https://api.companieshouse.gov.uk/search/companies/'
mydata <- GET(url, config = add_headers(paste0("Basic ", mkey)))
mydata
firmNAME <- gsub(" ", "+", company)
firmNAME <- gsub("&","%26", firmNAME)
FIRMurl <- paste0("https://api.companieshouse.gov.uk/search/companies/q=", firmNAME)
FIRMurl
mydata <- GET(url, config = add_headers(paste0("Basic ", mkey)))
firmTEST <- httr::GET(FIRMurl, httr::authenticate(mkey, ""))
httr::GET(FIRMurl, httr::authenticate(mkey, ""))
httr::GET(FIRMurl, httr::authenticate(mkey, "", type = 'basic'))
url
url <- "https://api.companieshouse.gov.uk/search/companies/"
httr::GET(url, httr::authenticate(mkey, "", type = 'basic'))
CH_API <- mkey
mkey
CH_API <- mkey
API_PATH <- 'https://api.companieshouse.gov.uk'
q <- 'Bernard Ecclestone'
q <- 'Bernard Ecclestone'
n <- 50
si <- ''
URL <- paste(API_PATH, '/search/officers?q=', URLencode(q), '&items_per_page=', n, '&start_index', si, sep = '')
URL
GET(URL,authenticate(CH_API_TOKEN, "", type = 'basic'))
CH_API_TOKEN <- mkey
API_PATH <- 'https://api.companieshouse.gov.uk'
q <- 'Bernard Ecclestone'
n <- 50
si <- ''
URL <- paste(API_PATH, '/search/officers?q=', URLencode(q), '&items_per_page=', n, '&start_index', si, sep = '')
GET(URL,authenticate(CH_API_TOKEN, "", type = 'basic'))
URL
authenticate(CH_API_TOKEN, "", type = 'basic')
library(httr)
library(jsonlite)
library(dplyr)
library(plyr)
mkey <- 'rgORvmllH4onBqmb0Gh5pOeW6zIB_G3zaavbgPyg'
company <- "unilever"
CompanySearch <- function(company, mkey) {
firmNAME <- gsub(" ", "+", company)
firmNAME <- gsub("&","%26", firmNAME)
FIRMurl <- paste0("https://api.companieshouse.gov.uk/search/companies?q=", firmNAME)
firmTEST <- httr::GET(FIRMurl, httr::authenticate(mkey, ""))
firmTEXT <- httr::content(firmTEST, as = "text")
JLfirm <- jsonlite::fromJSON(firmTEXT, flatten=TRUE)
MM <- JLfirm$total_results
MM2 <- MM/JLfirm$items_per_page
MM2b <- ceiling(MM2)
DFfirmL <- list()
for (j in 1:MM2b){
FIRMurl2<-paste0("https://api.companieshouse.gov.uk/search/companies?q=", firmNAME, "&page_number=",j)
firmTEST2 <- httr::GET(FIRMurl2, httr::authenticate(mkey, ""))
firmTEXT2 <- httr::content(firmTEST2, as = "text")
JLfirm2 <- jsonlite::fromJSON(firmTEXT2, flatten = TRUE)
DFfirmL[[j]] <- JLfirm2
}
DFfirm<-plyr::ldply(DFfirmL, data.frame)
DFfirmNAMES <- DFfirm$items.title
DFfirmNUMBER <- as.character(DFfirm$items.company_number)
DFfirmDateofCreation <- DFfirm$items.date_of_creation
DFfirmTYPE <- DFfirm$items.company_type
DFfirmSTATUS <- DFfirm$items.company_status
DFfirmADDRESS <- DFfirm$items.address_snippet
#DFfirmCOUNTRY<-DFfirm$items.address.country
DFfirmLOCAL <- DFfirm$items.address.locality
DFfirmPOSTCODE <- DFfirm$items.address.postal_code
myDf <- data.frame(
id.search.term = company,
company.name = DFfirmNAMES,
company.number = DFfirmNUMBER,
Date.of.Creation = DFfirmDateofCreation,
company.type = DFfirmTYPE,
company.status = DFfirmSTATUS,
address = DFfirmADDRESS,
Locality = DFfirmLOCAL,
postcode = DFfirmPOSTCODE)
return(myDf)
}
CompanySearch(company, mkey)
firmNAME <- gsub(" ", "+", company)
firmNAME <- gsub("&","%26", firmNAME)
FIRMurl <- paste0("https://api.companieshouse.gov.uk/search/companies/q=", firmNAME)
CH_API_TOKEN <- mkey
API_PATH <- 'https://api.companieshouse.gov.uk'
q <- 'Bernard Ecclestone'
n <- 50
si <- ''
URL <- paste(API_PATH, '/search/officers?q=', URLencode(q), '&items_per_page=', n, '&start_index', si, sep = '')
GET(URL,authenticate(CH_API_TOKEN, "", type = 'basic'))
GET(url = 'https://api.companieshouse.gov.uk/company/00002065', config = authenticate(mkey))
GET(url = 'https://api.companieshouse.gov.uk/company/00002065', add_headers(Authorization = mkey))
GET('https://api.companieshouse.gov.uk/company/00002065', add_headers(Authorization = mkey))
GET('https://api.companieshouse.gov.uk/company/q=00002065', add_headers(Authorization = mkey))
GET('https://api.companieshouse.gov.uk/company/00000006', add_headers(Authorization = mkey))
log(5)
library(data.table)    # High speed processing
library(dplyr)         # Data manipulation
library(purrr)         # Used for list merge (Reduce function)
library(tidyr)         # Used for data manipulation
library(lubridate)     # Working with date objects
0.0274log(14) + 0.0313
(0.0274 * log(14)) + 0.0313
log_func <- function(x) {
(0.0274 * log(x)) + 0.0313
}
log_func(14)
(0.0274 * log(x)) + 0.0313
log_func <- function(x) {
(0.0274 * log(x)) + 0.0313
}
log_func(14)
vec <- seq(0,60)
vec
sapply(vec, log_func)
log_results <- sapply(vec, log_func)
log_results <- data.frame(sapply(vec, log_func))
log_results
write.csv(log_results, 'log_trendline_results.csv')
log_func <- function(x) {
(0.0274 * log(x)) + 0.0313
}
log_func(14)
vec <- seq(0,60)
log_results <- data.frame(vec, sapply(vec, log_func))
write.csv(log_results, 'log_trendline_results.csv', row.names = FALSE)
install.packages('rPython')
install.packages('rPython-win')
install.packages('reticulate')
py_available()
install.packages('reticulate')
library(reticulate)
py_available()
library(reticulate)
py_available()
library(reticulate)
version
install.packages("installr"); library(installr) # install+load installr
updateR()
version
version
library(reticulate)
loading_packages <- c('data.table',                      # reading and processing big data
'foreign',                         # reading specific data file types
'DBI',                             # communication between R and RDBMS
'RMySQL','RPostgresSQL','RSQLite', # specific RDB packages
'haven', 'foreign',                # read & write from SAS, SPSS and Stata
'XLConnect', 'xlsx'                # read & write from Excel
)
manipulating_packages <- c('dplyr',      # essential for simple data manipulation
'tidyr',      # changing layout of data set (includes gather and spread)
'stringr',    # regular expressions and character strings
'lubridate',  # working with dates
'doBy',       # functions for groupwise computations of summary statistics
'tidyverse',  # essential for simple data manipulation
'rebus'       # verbose regular expressions
)
visualising_packages <- c('ggplot2',      # essential for creating charts
'ggvis',        # interactive web based graphics
'rgl',          # interactive 3D visualisations
'htmlwidgets',  # used to build interactive Javascript based visualisations
'ggthemes'      # themes for plots
)
modelling_packages <- c('car',            # used for ANOVA functions
'mgcv',           # generalised additive models
'lme4', 'nlme',   # linear & non-linear mixed effects models
'randomForest',   # random forest methods
'multicomp',      # multiple comparison testing
'vcd',            # vis tools and tests for categorical data
'glmnet',         # lasso and elastic-net regression methods with cross validation
'survival',       # survival analysis
'caret',          # training regression & classification models
'rpart',          # recursive partitioning and regression trees
'e1071',          # numerous functions for machine learning (SVM, Naive Bayes...)
'nnet',           # feed forward neural nets & multinomial log-linear models
'ROCR',           # visualise performance of classifiers
'igraph',         # network analysis tools
'kernlab',        # kernel-based machine learning
'gbm',            # generalised boosted regression models
'party',          # lab for recursive partitioning
'arules',         # mining association rules
'tree',           # classification & regression trees
'MICE',           # handling missing values
'infer'           # for A/B testing
)
reporting_packages <- c('shiny',      # interactive web apps
'RMarkdown',  # essential for reproducible reporting
'xtable'      # functions for returning HTML/latex code of datasets
)
spatial_packages <- c('sp', 'maptools',  # loading and using spatial data
'maps',            # easy-to-use map polygons for plots
'ggmap'            # use google maps as backgrounds in ggplots
)
financial_packages <- c('zoo',       # essential for time series data work
'quantmod',  # downloading, plotting and analysing financial data
'xts'        # flexible tool for manipulating time series data
)
big_data_packages <- c('Rcpp',         # functions that call C++ code for speed
'data.table',   # essential for big data - very fast operations
'parallel'      # use parallel processing to speed up crunch time
)
web_packages <- c('httr',      # working with http connections
'XML',       # read & create XML documents
'jsonlite',  # read & create JSON data tables
'RSelenium'  # working with web scraping
)
other_packages <- c('devtools',    # tools for turing code into a package
'testthat',    # writing unit tests for code projects
'roxygen2'     # document your packages
)
# Install packages --------------------------------------------------------
install.packages(pkgs = loading_packages, dependencies = TRUE,  repos = 'http://cran.rstudio.com')
install.packages(pkgs = manipulating_packages, dependencies = TRUE,  repos = 'http://cran.rstudio.com')
install.packages(pkgs = visualising_packages, dependencies = TRUE,  repos = 'http://cran.rstudio.com')
install.packages(pkgs = modelling_packages, dependencies = TRUE,  repos = 'http://cran.rstudio.com')
install.packages(pkgs = reporting_packages, dependencies = TRUE,  repos = 'http://cran.rstudio.com')
install.packages(pkgs = spatial_packages, dependencies = TRUE,  repos = 'http://cran.rstudio.com')
install.packages(pkgs = financial_packages, dependencies = TRUE,  repos = 'http://cran.rstudio.com')
install.packages(pkgs = big_data_packages, dependencies = TRUE,  repos = 'http://cran.rstudio.com')
install.packages(pkgs = web_packages, dependencies = TRUE,  repos = 'http://cran.rstudio.com')
install.packages(pkgs = other_packages, dependencies = TRUE,  repos = 'http://cran.rstudio.com')
library(reticulate)
py_available()
install.packages('reticulate')
py_available()
library(reticulate)
py_available()
library(reticulate)
setwd('C:/Users/Edward Sims/Documents/ml_projects/nerdycat/m3-update-dashboard')
# load twitter library - the rtweet library is recommended now over twitteR
library(rtweet)
# plotting and pipes - tidyverse!
library(ggplot2)
library(dplyr)
# text mining library
library(tidytext)
library(lubridate)
# whatever name you assigned to your created app
appname <- "m3-update-dashboard"
## api key (example below is not a real key)
consumer_key <- "Gnh1aBtqk3uOsvzml34nhD5Vi "
## api secret (example below is not a real key)
consumer_secret <- "9G4SzPHTGyOxotER6FNQ1V0cPoEaqtGMz5LppnxNtAptGbKd2X"
access_token <- "1145695972045053952-DK7zJOyY72DIO07tgolAwsXYs7f50Q"
# create token named "twitter_token"
twitter_token <- create_token(
app = appname,
consumer_key = consumer_key,
consumer_secret = consumer_secret,
access_token=access_token,
access_secret=access_secret)
tweets <- search_tweets(q = "-filter:retweets m3 congestion",
n = 500,
lang = 'en')
access_secret <- "NbdyCThQUZ7CU2JX0NrN9ilp7cU3N5EQ7EiolzcbOaD8P"
cols_keep <- c('created_at','screen_name','text','location','country')
tweets_sub <- tweets[, cols_keep]
this_week <- today() - 7
tweets_this_week <- as.data.frame(tweets_sub[tweets_sub$created_at >= this_week, ])
tweets_this_week <- tweets_this_week[tweets_this_week$screen_name != 'CapeTownFreeway', ]
tweets_this_week <- tweets_this_week[tweets_this_week$screen_name != 'TrafficSA1', ]
tweets_this_week <- tweets_this_week[tweets_this_week$screen_name != 'netstartraffic', ]
tweets_this_week <- tweets_this_week[tweets_this_week$screen_name != 'QLDTrafficMetro', ]
write.csv(tweets_this_week, 'tweets.csv')
